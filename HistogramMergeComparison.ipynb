{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantitative Accuracy Comparison Across Histogram Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run preamble.py\n",
    "%matplotlib inline\n",
    "\n",
    "from itertools import zip_longest\n",
    "from circllhist import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 74512\n",
      "-rw-r--r-- 1 jovyan users 17905959 May  8 19:58 1440-60.tsv\n",
      "-rw-r--r-- 1 jovyan users 16981727 May  8 20:21 24-3600.tsv\n",
      "-rw-r--r-- 1 jovyan users 37884449 May  8 19:58 4320-60.tsv\n",
      "-rw-r--r-- 1 jovyan users   745516 May  8 19:58 60-60.tsv\n"
     ]
    }
   ],
   "source": [
    "!ls -l datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNT=24\n",
    "PERIOD=60*60\n",
    "FILENAME=\"datasets/{}-{}.tsv\".format(COUNT,PERIOD)\n",
    "\n",
    "def parse_line(l):\n",
    "    b, v = l.split(\"\\t\")\n",
    "    return int(b), float(v)\n",
    "\n",
    "raw_batches = [ [] for _ in range(COUNT + 1) ]\n",
    "with open(FILENAME) as fh:\n",
    "    for line in fh:\n",
    "        batch_id, val = parse_line(line)\n",
    "        if(batch_id >= COUNT):\n",
    "            print(line)\n",
    "        raw_batches[batch_id].append(val)\n",
    "\n",
    "# Eliminate empty batches\n",
    "raw_batches = list(filter(lambda l:len(l) > 0, raw_batches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total R\n",
    "raw_total = np.concatenate(raw_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false\n",
    "## VISUALS ##\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "BATCH_SKIP=100\n",
    "SKIP=50\n",
    "AX_COUNT=int(COUNT/BATCH_SKIP)\n",
    "fig = plt.figure(figsize=(30,.5*AX_COUNT))\n",
    "fig.subplots_adjust(hspace = .8)\n",
    "for i,batch in enumerate(raw_batches):\n",
    "    if (i % BATCH_SKIP != 0): continue\n",
    "    ax = plt.subplot(AX_COUNT,1,int(i/BATCH_SKIP)+1)\n",
    "    ax.set_xlim(0,500)\n",
    "    sns.rugplot(batch[::SKIP], ax=ax, alpha=0.5,height=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exact computations\n",
    "\n",
    "For this example we will use the following statistics:\n",
    "\n",
    "- mean\n",
    "- median\n",
    "- p95, p99, p99.9\n",
    "- max\n",
    "\n",
    "and compare the relative errors, of the merged data to the precise data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = \"mean median p95 p99 p999 p9999 max\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_np = {\n",
    "    \"mean\"   : lambda R: np.mean(R),\n",
    "    \"median\" : lambda R: np.percentile(R, 50),\n",
    "    \"p95\"    : lambda R: np.percentile(R, 95),\n",
    "    \"p99\"    : lambda R: np.percentile(R, 99),\n",
    "    \"p999\"    : lambda R: np.percentile(R, 99.9),\n",
    "    \"p9999\"    : lambda R: np.percentile(R, 99.99),\n",
    "    \"max\"    : lambda R: np.percentile(R, 100),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_total = { k : stats_np[k](raw_total) for k in stats }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True stats of the merged dataset\n",
      "                mean              median                 p95                 p99                p999               p9999                 max\n",
      "             195.397              65.515             290.726            3468.665           18774.050           34244.469           41989.939\n"
     ]
    }
   ],
   "source": [
    "print(\"True stats of the merged dataset\")\n",
    "\n",
    "def relative_error_pct(true_val, val):\n",
    "    delta = val - true_val\n",
    "    return delta / true_val * 100\n",
    "\n",
    "def p_head(prefix):\n",
    "    print(prefix + \"\".join([ \"{:>20}\".format(k) for k in stats]))\n",
    "def p_rec(prefix, rec):\n",
    "    print(prefix + \"\".join([ \"{:>20.3f}\".format(rec[k]) for k in stats]))\n",
    "def p_report(name, stats_t):\n",
    "    stats_err = { k: relative_error_pct(stats_total[k], stats_t[k]) for k in stats }\n",
    "    p_rec(name + \"      \", stats_t)\n",
    "    p_rec(name + \" ERR% \", stats_err)\n",
    "    \n",
    "p_head(\"\")\n",
    "p_rec(\"\", stats_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Aggregation: Mean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row wise statistics:\n",
    "SL = [ { k : stats_np[k](B) for k in stats }  for B in raw_batches ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch                mean              median                 p95                 p99                p999               p9999                 max\n",
      "    0               48.166              37.660              76.092             353.212            1385.642            3756.790            4477.232\n",
      "    1               61.119              51.736              84.757             363.757            1883.959            3833.551            4639.391\n",
      "    2               75.071              64.348              98.255             371.042            2858.847            4207.381            9142.573\n",
      "    3              115.738              65.391             238.052            1338.533            5273.472            8206.849            8737.645\n",
      "    4              127.681              72.844             302.986            1541.056            3907.465            5793.125            6720.831\n",
      "    5              312.985              76.067             318.590            8527.715           10414.728           10498.235           10507.513\n",
      "    6              126.631              82.017             391.004             529.371             571.810             577.162             577.757\n",
      "    7              138.039              82.437             295.821             390.663             398.689             399.492             399.581\n",
      "    8               90.359              77.987             269.818             326.949             438.921             450.118             451.362\n",
      "    9              481.974             105.773            1655.900            5100.900           14781.303           15749.343           15856.903\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "p_head(\"batch\")\n",
    "for i,S in enumerate(SL[:10]):\n",
    "    p_rec(\"{:>5} \".format(i), S)\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             mean              median                 p95                 p99                p999               p9999                 max\n",
      "                          195.397              65.515             290.726            3468.665           18774.050           34244.469           41989.939\n",
      "Average                   159.102              70.081             396.729            2259.214            5154.266            7237.445            8672.218\n",
      "Average ERR%              -18.575               6.970              36.462             -34.868             -72.546             -78.865             -79.347\n"
     ]
    }
   ],
   "source": [
    "stats_avg = { k : np.mean([ S[k] for S in SL ]) for k in stats }\n",
    "\n",
    "p_head(\"             \")\n",
    "p_rec(\"             \",stats_total)\n",
    "p_report(\"Average\", stats_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HRD Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circllhist_from_valuelist(L):\n",
    "    H = Circllhist()\n",
    "    for v in L: H.insert(v)\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "HL = [ circllhist_from_valuelist(B) for B in raw_batches  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "HT = Circllhist()\n",
    "for H in HL:\n",
    "    HT.merge(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_circllhist_f = { \n",
    "    \"size\" : lambda H: len(H.to_b64())/4*3,\n",
    "    \"mean\" : lambda H: H.mean(),\n",
    "    \"median\" : lambda H : H.quantile(.5),\n",
    "    \"p95\" : lambda H : H.quantile(.95),\n",
    "    \"p99\" : lambda H : H.quantile(.99),\n",
    "    \"p999\" : lambda H : H.quantile(.999),\n",
    "    \"p9999\" : lambda H : H.quantile(.9999),\n",
    "    \"max\" :   lambda H : H.quantile(1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_circllhist = { k : stats_circllhist_f[k](HT) for k in stats }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                mean              median                 p95                 p99                p999               p9999                 max\n",
      "                             195.397              65.515             290.726            3468.665           18774.050           34244.469           41989.939\n",
      "CIRCLLHIST                   195.472              65.513             290.663            3469.678           18728.847           34201.988           42000.000\n",
      "CIRCLLHIST ERR%                0.038              -0.003              -0.022               0.029              -0.241              -0.124               0.024\n"
     ]
    }
   ],
   "source": [
    "p_head(\"                \")\n",
    "p_rec(\"                \",stats_total)\n",
    "p_report(\"CIRCLLHIST\", stats_circllhist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-Digest\n",
    "\n",
    "Python version can't do merges, so we use a JAVA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HistogramMergeTool\n",
      "- Input Quantile: 0.500000\n",
      "- Input Quantile: 0.900000\n",
      "- Input Quantile: 0.950000\n",
      "- Input Quantile: 0.990000\n",
      "- Input Quantile: 0.999000\n",
      "- Input Quantile: 0.999900\n",
      "- Input Quantile: 1.000000\n",
      "Merging  24 batches\n",
      "size\t1468\n",
      "q0.500000\t65.735235\n",
      "q0.900000\t114.754051\n",
      "q0.950000\t300.677732\n",
      "q0.990000\t3494.516689\n",
      "q0.999000\t18787.130406\n",
      "q0.999900\t34268.529730\n",
      "q1.000000\t41989.938660\n"
     ]
    }
   ],
   "source": [
    "!cat $FILENAME | java -jar tdigest-merge-tool.jar .5 .9 .95 .99 .999 .9999 1 | tee results.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TDigest                       nan              65.735             300.678            3494.517           18787.130           34268.530           41989.939\n",
      "TDigest ERR%                  nan               0.337               3.423               0.745               0.070               0.070               0.000\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "def import_results():\n",
    "    with open(\"results.tsv\") as fh:\n",
    "        lines = fh.readlines()\n",
    "    pairs = [ l.strip().split(\"\\t\") for l in lines ]\n",
    "    return {\n",
    "        k : float(v) for k,v in pairs\n",
    "    }\n",
    "\n",
    "res = import_results();\n",
    "\n",
    "stats_td = {\n",
    "    \"size\" : res[\"size\"],\n",
    "    \"mean\" : np.NAN, # not given\n",
    "    \"median\" : res[\"q0.500000\"],\n",
    "    \"p95\"  : res[\"q0.950000\"],\n",
    "    \"p99\"  : res[\"q0.990000\"],\n",
    "    \"p999\" : res[\"q0.999000\"],\n",
    "    \"p9999\": res[\"q0.999900\"],\n",
    "    \"max\"  : res[\"q1.000000\"],\n",
    "}\n",
    "\n",
    "p_report(\"TDigest\", stats_td)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "### Merging 24 batches @ 3600 seconds ###\n",
      "\n",
      "\n",
      "                                mean              median                 p95                 p99                p999               p9999                 max\n",
      "TOTAL:                       195.397              65.515             290.726            3468.665           18774.050           34244.469           41989.939\n",
      "\n",
      "AVG                          159.102              70.081             396.729            2259.214            5154.266            7237.445            8672.218\n",
      "AVG        ERR%              -18.575               6.970              36.462             -34.868             -72.546             -78.865             -79.347\n",
      "\n",
      "CIRCLLHIST                   195.472              65.513             290.663            3469.678           18728.847           34201.988           42000.000\n",
      "CIRCLLHIST ERR%                0.038              -0.003              -0.022               0.029              -0.241              -0.124               0.024\n",
      "\n",
      "TDigest                          nan              65.735             300.678            3494.517           18787.130           34268.530           41989.939\n",
      "TDigest    ERR%                  nan               0.337               3.423               0.745               0.070               0.070               0.000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n### Merging {} batches @ {} seconds ###\\n\\n\".format(COUNT, PERIOD))\n",
    "p_head(\"                \")\n",
    "p_rec(\"TOTAL:          \", stats_total)\n",
    "print()\n",
    "p_report(\"AVG       \", stats_avg)\n",
    "print()\n",
    "p_report(\"CIRCLLHIST\", stats_circllhist)\n",
    "print()\n",
    "p_report(\"TDigest   \", stats_td)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
